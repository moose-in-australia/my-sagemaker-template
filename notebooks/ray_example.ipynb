{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebd369f",
   "metadata": {},
   "source": [
    "# Example notebook for using Ray with Amazon SageMaker Training Jobs\n",
    "\n",
    "This notebook describes my best practices for using Ray distributed training in Amazon SageMaker training jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f2f32",
   "metadata": {},
   "source": [
    "The cell below shows the basic structure you should use for your training code. It shows:\n",
    "\n",
    "* How to apply logging\n",
    "* How to set up MLflow\n",
    "* How to detect and set the workers and GPUs\n",
    "\n",
    "Remember, we use PyTorch Lightning as our preferred framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b83601",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ../scripts/train.py\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import ray\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import sagemaker_training.environment\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    data_path = os.environ.get(\"SM_CHANNEL_TRAIN\", \".\")\n",
    "    model_path = os.environ.get(\"SM_MODEL_DIR\", \"./model/\")\n",
    "\n",
    "    # Continue your training code here\n",
    "\n",
    "\n",
    "def setup_workers(env):\n",
    "    \"\"\"Configure worker settings based on available resources.\"\"\"\n",
    "    num_gpus = int(ray.available_resources().get(\"GPU\", 0))\n",
    "    num_cpus = int(ray.available_resources().get(\"CPU\", env.num_cpus))\n",
    "    logger.info(f\"Found {num_gpus} GPUs, {num_cpus} CPUs\")\n",
    "\n",
    "    if env.is_hetero:\n",
    "        logger.info(\"Heterogeneous cluster detected\")\n",
    "        all_hosts = []\n",
    "        for instance_group in env.instance_groups_dict.values():\n",
    "            if instance_group[\"instance_group_name\"] != env.current_instance_group:\n",
    "                group_hosts = instance_group[\"hosts\"]\n",
    "                all_hosts.extend(group_hosts)\n",
    "        # Multi-node vs single-node setup\n",
    "        num_workers = num_gpus if num_gpus > 0 else len(all_hosts)\n",
    "    else:\n",
    "        logger.info(\"Homogeneous cluster detected\")\n",
    "        # Multi-node vs single-node setup\n",
    "        num_workers = num_gpus if num_gpus > 0 else len(env.hosts)\n",
    "\n",
    "    logger.info(f\"Number of workers: {num_workers}\")\n",
    "\n",
    "    return num_workers, num_gpus\n",
    "\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Fetching parameters\")\n",
    "    hyperparams = json.loads(os.environ[\"SM_HPS\"])\n",
    "    env = sagemaker_training.environment.Environment()\n",
    "    num_workers, num_gpus = setup_workers(env)\n",
    "    \n",
    "    logger.info(\"Initializing MLflow\")\n",
    "    mlflow.enable_system_metrics_logging()\n",
    "    mlflow.autolog()\n",
    "    try:\n",
    "        mlflow_arn = str(os.environ.get(\"MLFLOW_TRACKING_ARN\"))\n",
    "        mlflow_experiment = str(os.environ.get(\"MLFLOW_EXPERIMENT_NAME\"))\n",
    "    except Exception as error:\n",
    "        logger.error(f\"Can't fetch MLflow details: {error}\", exc_info=True)\n",
    "        raise\n",
    "    mlflow.set_tracking_uri(mlflow_arn)\n",
    "    mlflow.set_experiment(mlflow_experiment)\n",
    "    \n",
    "    logger.info(\"Starting training run\")\n",
    "    with mlflow.start_run():\n",
    "        # Continue your code here\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as error:\n",
    "        logger.error(f\"Training failed: {error}\", exc_info=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97eaf67",
   "metadata": {},
   "source": [
    "Since we use Amazon SageMaker Unified Studio, our project has a designated S3 bucket and prefix which we need to use. Note: SageMaker Sessions are also different between SageMaker AI Studio and SageMaker Unified Studio! The correct import for Unified Studio is shown in the cell below. \n",
    "\n",
    "We use the PyTorch 2.7.1 training image by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff37afb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.modules import Session\n",
    "\n",
    "s3_uri = project.s3.root\n",
    "bucket, prefix = s3_uri.replace('s3://', '').split('/', 1)\n",
    "sagemaker_session = Session(\n",
    "    default_bucket=bucket,\n",
    "    default_bucket_prefix=prefix\n",
    ")\n",
    "\n",
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.7.1\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131920c",
   "metadata": {},
   "source": [
    "Although there are multiple ways to create a SageMaker training job, we prefer using the newer ModelTrainer class. See example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae766e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import (\n",
    "    Compute,\n",
    "    OutputDataConfig,\n",
    "    SourceCode,\n",
    "    StoppingCondition,\n",
    "    InputData,\n",
    ")\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "job_name = f\"ray-training-job-{timestamp}\"\n",
    "output_path = f\"{project.s3.root}/{job_name}\"\n",
    "\n",
    "# Define the source code configuration\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"../scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    entry_script=\"launcher.py\",\n",
    ")\n",
    "\n",
    "# Define compute configuration\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=3,\n",
    "    keep_alive_period_in_seconds=0,\n",
    ")\n",
    "\n",
    "# Create the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    training_image=image_uri,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    environment={\n",
    "        \"entry_script\": \"train.py\",\n",
    "        \"MLFLOW_TRACKING_ARN\": mlflow_server_arn,\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": \"initial-tests\"\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"n_factors\": 10,\n",
    "        \"sample_size\": 500,\n",
    "        \"epochs\": 20,\n",
    "    },\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=10800),\n",
    "    output_data_config=OutputDataConfig(s3_output_path=output_path),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
